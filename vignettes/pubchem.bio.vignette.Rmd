---
title: "pubchem.bio.vignette"
author: "Corey Broeckling"
date: "`r Sys.Date()`"
version: 0.9.0.0
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Background

Metabolomic approaches utilize analytical instrumentation to detect and quantify small molecules.  The chemical space covered by metabolomics is massive, with more than 100 million structures in Pubchem.  Efforts to curate custom metabolome databases, such as the Human Metabolome Database (https://www.hmdb.ca/) are incredibly valuable, enabling annotation efforts to focus on only those chemicals most likely to be found in the samples being analyzed.  Metabolomics, however, is well suited the analysis of metabolomes from any species, and there are few taxonomically informed databases available.  

Pubchem, which is a massive repository of chemical structures, is also extremely rich in chemical metadata.  Several biologicallly-focused metabolomic databases have deposited their structures data in Pubchem, thousands of metabolic pathways are present, and there are rich taxonomic-structure pairs.  

This package enables researchers to bring Pubchem onto their local computer, and parse it to develop
1. a metabolomic structure database of all biological compounds in Pubchem and
2. custom metabolomic structure databases using all available taxonomic data in Pubchem. 

##  Installation
```{r installation, eval=FALSE}
install.packages(pubchem.bio, depencies = TRUE)
```

## System requirements
Pubchem is a very large database. The pubchem.bio package does not download _ALL_ of pubchem.  It does however download every structure, inchikey, smiles, and several other basic descriptors.  As such, while the package is designed to minimize computational overhead, you will still want to have sufficient disk space and RAM to ensure that processing doesn't bog down during parsing and organizing files.  

It is recommended that you perform these functions on a computer with at least 200 GB local SSD disk space, since a great deal of reading and writing of data will be occurring.  Further, during processing, there will be large files that are being handled in memory, so it is recommended that you utilize a computer with at least 64 GB of RAM.  Parallel processing is enabled through the doParallel and foreach packages, which will speed up processing time, but this will still take several hours.  Do note that parallel processing results in increased RAM consumption.  If your run out of RAM, the process will become extremely slow and could crash R/Rstudio.  If you are RAM limited, you are probably going to have more success using fewer threads.  The download process performance is also going to be dependent on network stability and speed.  

Running the program on a windows 11 PC, with 64 GB RAM, a local SSD hard drive, and setting threads = 8 in all functions, the full processing time for all steps scripted below was about ________.  

## Practical note on Rsession crash observations, before we continue: 
The functions in this package do relatively big things - lots of data handling, reshuffling, etc.  While the package code is stable most of the time, in Rstudio GUI, have experienced some instability: when running some functions some of the time in Rstudio GUI i have seen Rsession crashes.  I beleive it has something to do with issues described here: 'https://github.com/rstudio/rstudio/issues/15330'.  When running the code below from a script using the R Rscript.exe program, the functions are stable.  When running these in the native Rgui.exe program, the functions are stable.  I have seen the functions stable on some versions of R/Rstudio/Windows combinations in the Rstudio GUI.  So if you see instability, please first try saving your code in an R script, and running it from your command line - something like 'C:/Programs/R.../Rscript.exe' 'my.pubchem.bio.Rscript.R'.  You can also try running this as a background job in Rstudio - this is actually recommended for large complex code sets.  

## Running the code
This isn't a complex package, there are relatively few functions.  All functions start with 'get', 'build', or 'export'.  'get' functions download data to your local drive, 'build' functions parse and organize the downloaded data to turn it into something more useful for metabolomic scientists, and 'export' functions write these metabolome datasets to file for use in other programs.  

_I AM GOING TO BE WORDY HERE, BUT PLEASE READ THIS, AS IT WILL HELP YOU APPLY THE pubchem.bio PACKAGE TO YOUR NEEDS._ 

### Downloading all the PubChem we need
First thing we need to do is get pubchem data local to your computer.  

#### note that running this line of code may occupy your R session for 2-3 few hours

```{r get.pubchem, eval=FALSE}
pubchem.bio::get.pubchem.ftp(pc.directory ="C:/Temp/20250701")

```


What just happened?  We have downloaded a bunch of data, mostly from the Pubchem FTP site.  These downloaded compressed files were decompressed, and we extracted only the most relevant bits of data from them, saving those relevant bits as data.tables in .Rdata format.  The temporary files were removed after processing is done (assuming rm.tmp.files = TRUE).  We did not build a database, we simply moved all the data we want from remote to local, and discarded data we have no need for to keep from cluttering up our hard drive and memory. 

### Building metabolite (CID) - lowest common ancestor (LCA) relationships
Our next step needs to be further organization of taxonomy data.  This will be done using the 'build.cid.lca' function.  The downloaded data is currently in a format containing three columns, a taxonomy ID, a Pubchem CID, and the source of the relationship information.  This is a nice, clean format.  However, taxonomy is heirarchical, and the pubchem.bio package aims to use that heirarchy.  The 'build.taxid.lca function organizes the chemical relationships into the taxonomic heirarchy, so that we can utilize this heirarchy in building taxon-specific metabolomics databases.  The principle on which the process is based is the 'lowest common ancestor' approach.   As an example, the lowest common ancestor, from a taxonomy perspective, of the two species [_Homo heidelbergensis_](https://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?lvl=0&amp;id=1425170) and [_Homo sapiens_](https://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?mode=Tree&id=9606) is the genus [_Homo_](https://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?mode=Undef&id=9605).  Note that this LCA is a property of a graph, in computer science, but i opted to organize this as a data.table, as recovering LCA was faster (for me at least) in this format than in graph format.

To build the cid.lca relationships, we need to define which 'sources' of taxonomy information we wish to use.  for this example, we will just use LOTUS, but there are many options.  I will discuss the importance of this below, but for now, here is the code we can use to infer LCA for each CID.  

#### note that running this line of code may will take about an hour of computer time, with 8 threads, 64 GB RAM
```{r build.cid.lca, eval=FALSE}
build.cid.lca(pc.directory = "C:/Temp/20250701", tax.sources =  "LOTUS - the natural products occurrence database")
```

This function builds the CID - LCA relationship for all compounds with taxonomy data.  Note that you can optionally use pathway information in your taxonomy source data as well. In the case of pathway data, there are conserved and species specific pathways.  Conserved pathways are considered to have an LCA = 1, or 'root' taxonomy, and therefore can be used to ensure that the TCA cycle metabolites, for example, are going to be included in any metabolomic database generated (they would be anyway - this is a trivial example), even if there is no specific evidence that it is present in your species of interest.  By default 'use.conserved.pathways' is set to 'FALSE', as 'conserved' can mean different things to different people.


### Creating PubChem BIO metabolome database.  
We can now build a databae of biological compounds as a subset of Pubchem data.  We base this on (1) BIO databases as a source (2) pathway data and (3) taxonomy data.   If you would like to see the full list of all sources, please go to Pubchem: https://pubchem.ncbi.nlm.nih.gov/sources/.  Currently, the default uses bio.sources = c("Metabolomics Workbench","Human Metabolome Database (HMDB)", "ChEBI", "LIPID MAPS", "MassBank of North America (MoNA)").  All pathway metabolites are added, as are all metabolites from the taxonomy dataset.  You can specify to only include certain sources for each of pathways and taxonomy as well.  Generally, when compiling metabolomics databases, we want to remove salts, so that is done by default. We also can optionally calculate some basic physicochemical properties using rcdk.  While some of these are also available via pubchem, i have found it much faster to calculate them locally.  Let me know if you feel it important to change this behavior and actually use Pubchem predicted properties instead. 

#### note that running this line of code may will take about 1.5 hours of computer time, with 8 threads, 64 GB RAM
 
```{r build.pubchem.bio, eval=FALSE}
pc.bio <- build.pubchem.bio(pc.directory = "C:/Temp/20250703")
```


### Creating taxon-specific metabolite databases
By oraganizing taxonomy-metabolite data within the taxonomic heirarchy in cid-lca pairs (above), we can use some logical/reasoned steps to ensure that our taxonomy-specific metabolome database is as comprehensive as possible.   If we know that [capsaicin](https://pubchem.ncbi.nlm.nih.gov/compound/Capsaicin) is found in _Capsicum annuum_ and _Capsicum frutescens_ (amongst others), once can reasonably infer that capsaicin _could_ be found in other _Capsicum_ species, such as _Capsicum cornutum_ even if there is not any documented evidence of this in PubChem.  Therefore, if the only two know sources of Capsacin were the two Capsicum species, we can set the lowest common ancestor to _Capsicum_.  

This enables us to build a metabolome database for _Capsicum cornutum_ even if Pubchem had no information on _Capsicum cornutum_ metabolites, since we have defined many metabolites which associate with the _Capsicum_ genus, as well as with higher taxonomic levels. Lowest common ancestor values at higher taxonomic levels mean those metabolite-lca pairs represent more highly conserved metabolism.  

#### note that running this line of code may will take about a minute of computer time, with 8 threads, 64 GB RAM
 
```{r build.taxon.metabolome, eval=FALSE}
pc.bio.sub <- build.taxon.metabolome(taxid = 1710960, pc.directory = "C:/Temp/20250703", get.properties = FALSE)
```

#### meta-metabolomes
This function can also take a list of taxids. Imagine you are analyzing stool samples from a gut microbiome study under controlled diet conditions.  You can include human (9606), _Prevotella_ (838), _Bacterioides_ (816), _Capsicum_ (4071), _Bos taurus_ (9913), etc, by setting taxid = c(9606, 838, 816, 4071, 9913).  This tool does not try to predict cross-species metabolism, but you now have a metabolite database which you can provide to tools such as Biotransformer.  

### Creating taxon-scored metabolite databases
Additionally, since we have LCA assigned for as many pubchem CIDs as have taxonomy associations, we can also create similarity scores describing how closely associated the nearest known cid-lca pair for any given taxonomic level. This function takes the output from build.pubchem.bio as input, with a vector of taxids.  For each taxid, a score is assigned to each metabolite in the pubchem.bio dataset based on how where the cid's lca lands on that taxid's heirarchy.  if the taxid is at the genus level, and the lca is the same genus, the output similarity score will be 1.  if the taxid is at the genus level, and the lca is 1 (root), the score will be 0.  Further, if there is no lca assigned (as is the case for most of pubchem.bio compounds), the resulting score will be 0.   

__Approach note:__ This function is not building your taxonomy specific database, it is assigning a lowest common ancestory for every metabolite with supporting taxonomy data.  Ultimately, we will build the taxonomy specific databases from the output of this function, for any taxa we like.  Ultimately, you will still need to demonstrate, using analytical mass spectrometry, that capsaicin is actually present in the species (or not) - we are just defining chemical search space.   As such, I tend to approach this in an 'inclusive' manner - if a metabolite is plausibly present, i want it in the search space.

There are dedicated taxonomy-cid relationships defined by many groups, or in PubChem vernacular, 'sources'.  For example, if we look at the taxonomic relationships for capsaicin (see URL above), we see that it is noted to be found in various _Capsicum_ species, which is expected, but it is also noted to be found in humans through its presence in HMDB.  This record for humans is certainly true, in one sense - we humans often eat spicy peppers and therefore Capsaicin will be found in humans.  But it is not _produced_ by humans.  It is up to you whether you want to capture these sorts of relationships in your taxonomy data, and you have to execute that decision by choosing data sources appropriately.  



You can assign LCA to each metabolite using the 'build.taxid.lca' function.  You point the function to the directory you created in the above step, which contains all the relevant .Rdata Pubchem files.  You also will define which sources of 'taxonomy' you want to use.  



I have set the 'tax.sources' option default to be 'interactive' so that every time you can see the sources and decide.  However, you can also just set the sources as a character vector.  i.e. c("LOTUS - the natural products occurrence database") will ONLY use taxonomy-CID relationships as defined by LOTUS.  Also note that some sources appear to have what i would consider to be false positive assignments.  Capsicum is reported to be found in _Mango_ by the NPASS database.  This appears to be a product of automated text mining mis-assignment. Given that LOTUS seems to contain fewer of these (i have not been systematic or comprehensive in evaluating this), and is also massive, i generally _only_ use LOTUS, but this is ulitmately up to you to decide.  

As an example of why this all matters:  If you set 'tax.sources = c("LOTUS - the natural products occurrence database")', the LCA for Capsaicin is _Capsicum_, which make great sense, since this is the genus which contains all of the peppers we know and love.  However, if you use NPASS in your 'tax.sources' option, the lowest common ancestor for Capsacin changes from _Capsicum_  to Petapetalae, a clade containing all Asterids, Caryophyllales, Rosids, etc.  This would mean that if you built a species specific database for _Glycine max_, the common soybean, it _would_ contain Capsaicin, since it falls within the taxonomy structure headed by the LCA Pentapetalae: Pentapetalae/rosids/fabids/Fabales/Fabaceae/Papilionoideae/Phaseoleae/Glycine/max.  





This 'pc.bio' object contains > 1M metabolites (using default settings), and has columns with names, structures, and properties.   It can be used directly as a source dataset for export to spreadsheet format, as it is a data.frame object.  It includes metadata including the number of references to pubmed ('pmid.ct'), the number of sources that include this compound in their pubchem submission ('source.ct'), number of pathways that reference the compound ('pathway.ct') and the number of taxonomy relastionships defined ('taxonomy.ct').  These are only reported - it is up to you what to do with this information.  Some informatics tools rely heavily on such information to increase the true positive hits, while others vehemently eschew such approaches as it introduces bias into the analysis.  Additionally, we have now four rcdk-calculated properties, 'XLogP', 'nAcid', 'nBase', and 'TopoPSA'.  These properties are useful entry points into chemical descriptions that are of value in undersatnding analytical behavior. 'XLogP' as an estimator of neutral pH hydrophobicity, 'nAcid' and 'nBase' to describe ionizability, and 'TopoPSA' as a tool for understanding polarity in a manner dependent on molecular size.  


#### note that running this line of code may will take about a minute of computer time, with 8 threads, 64 GB RAM
 
```{r build.taxonomy.similarity.scores, eval=FALSE}
pc.bio.tax.scores <- build.taxonomy.similarity.scores(taxid = 4081, pc.directory = "C:/Temp/20250703", get.properties = FALSE)
```



